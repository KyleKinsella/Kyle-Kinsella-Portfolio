<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Summary of Linear Regression, Decision Trees and Random Forest Project Overviews</title>
    <link rel="stylesheet" href="template.css">
    <link rel="stylesheet" href="all.css">
</head>
<body>

    <style>
        .dvv {
            display: inline-block;
            align-items: center; 
            margin-bottom: 10px; 
        }
        .dvv, .features {
            display: flex;
            margin-left: 10px; 
            margin: -60px;
        }
    </style>


    <header>
        <div class="container">
            <h1>Summary of Linear Regression, Decision Trees and Random Forest Project Overviews for Data Science and Machine Learning 1</h1>
        </div>
    </header>


  <section id="summary">
        <div class="container">
            <h2>Summary</h2>

            <h4>What is Linear Regression and why use it?</h4> <br>
            <ul>
                <strong><h4>What is Linear Regression?</h4></strong>
                <li>Linear Regression is the use of an X and Y axis for a graph. We can have two or more bits of data on our graph. Normally we would have our data plotted 
                on the X and Y parts of the graph, then we would draw our linear regression line to see how good our data fits out model. If our data is too far away from 
                the line this means that our data is not good enough, or our data is overall bad. One of the main uses of linear regression is to try and predict new numbers based off 
                the previous numbers that our linear regression model has been trained on. <br><br>

                <strong><h4>Why use Linear Regression?</h4></strong>
                <li>If you want to use linear regression to try and predict a certain number or many other things. The best way to explain linear regression is 
                through the use of an example, see below: <br>
                if we have an array [1,2,3,4] and we train our linear regression model on this dataset our linear regression model will predict 
                the next number to be 5 and plot that accordingly on our graph, this is the heart of linear regression.</li> <br>
            </ul>

            <h4>What is Decision Tree and why use it?</h4> <br>
            <ul>
                <strong><h4>What is a Decision Tree?</h4></strong>
                <li>A Decision Tree is very similar to a binary search tree. A decision tree has two branches a true and false branch. In a node of a decision tree 
                there is a few important parts but the most important part is called "gini" also know as gini impurity. Gini impurity is a mathematical calculation to see how we can
                split the decision tree into the true and false branches, this is a very important part of a decision tree.</li> <br>

                <strong><h4>Why use a Decision Tree?</h4></strong>
                <li>If you want to be able to make an easy to understand diagram to show what you are trying to achieve then I would suggest you use a decision tree.
                There is a big problem with a decision tree that you need to be aware of a decision tree can over-fit the data too well. This means that that the 
                decision tree learns the data too well and as a result your decision tree will not be accurate and if you try and train your decision tree on a 
                new dataset this will not work because it has learnt the previous dataset to well. This is one of the biggest issues with decision trees.
                </li>
            </ul>

            <h4>What is Random Forest and why use it?</h4> <br>
            <ul>
                <strong><h4>What is a Random Forest?</h4></strong>
                <li>A Random Forest is identical to a decision tree, this is because a random forest is made up of many decision trees. If we want to try and stop
                over-fitting data to our above decision tree we can use a random forest to fix this issue. A random forests solve the problem of overfitting data
                because they combine the output of multiple decision trees to come up with a final prediction <a href="https://www.google.com/search?q=random+forest+vs+decision+tree&client=firefox-b-d&sca_esv=54bc90cb432fd13f&sxsrf=ADLYWIJ-7z_uCPeaaID1-Scy1ypNammdxA%3A1732389572268&ei=xCpCZ6aLEK-ohbIPkq6HqQM&oq=random+forest+vs+&gs_lp=Egxnd3Mtd2l6LXNlcnAiEXJhbmRvbSBmb3Jlc3QgdnMgKgIIADIKEAAYgAQYQxiKBTIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABEiADFDHAVizBXAAeAKQAQCYAYUDoAHfCaoBBTItMy4xuAEDyAEA-AEBmAIFoAKMCsICBBAAGEfCAgoQIxiABBgnGIoFmAMAiAYBkAYIkgcJMS4wLjIuMS4xoAeCGg&sclient=gws-wiz-serp">Random Forest VS Decision Tree</a>.
                </li> <br>

                <strong><h4>Why use a Random Forest?</h4></strong>
                <li>If you are trying to use a decision tree to train a big dataset but it has learnt the previous dataset to well and you want to stop the 
                overfitting I would recommend that you use a random forest this is because a random forest is trying to fix this issue that decision trees have.</li>
            </ul>
        </div>
    </section>


    <section id="about">
        <div class="container">
            <h2>Data Sources</h2>
            <!--<p>Linear regression ..., dt ..., rf ...</p>  I was going to do it like this but this is not a good idea--> 
        
            <h4>For all of my data sources for all three projects I used <a href="https://www.kaggle.com/">Kaggle</a> data.</h4> <br>

            <ul>
                <!-- Linear Regression part -->
                <h4>Linear Regression</h4>
                <li>During my linear regression project I found a dataset for sports. I was trying not to use kaggle data
                due to it being cleaned and pre-processed but I was unable to find any other good sports datasets elsewhere.</li> <br>

                <!-- Decision Tree part -->
                <h4>Decision Tree</h4>
                <li>I used the same dataset from my linear regression project, because it was easy to understand and use.</li> <br>

                <!-- Random Forest part -->
                <h4>Random Forest</h4>
                <li>I used the dataset that I used for my linear regression project and decision tree projects.</li> <br>
            </ul>
        </div>
    </section>



    <section id="about">
        <div class="container">
            <h2>Pre Processing</h2>
            <ul>
                <h4>Linear Regression</h4>     
                <li>During my linear regression project I did some pre-processing. I got my dataset
                and I split it into half to try and make the data easier to visualize but in the end I was not able to 
                visualize it even do I split the data to be very small.</li> <br>

                <h4>Decision Tree</h4>
                <li>During my decision tree project I made my initial dataset that was very small to be a bit bigger.</li> <br>
                
                <h4>Random Forest</h4>
                <li>Since I did not do any pre-processing for my decision tree project, I did not do any pre-processing my random forest project 
                because a random forest is made up of many decision trees.</li> <br>
            </ul>
        </div>
    </section>


    <section id="about">
        <div class="container">
            <h2>Data Understanding & Visualization</h2>
            
            <ul>
                <h4>Linear Regression</h4>     
                <li>During my linear regression project I encountered a few issues when making my model. Due to my dataset being very 
                small my data did not plot to well on my graph. <strong>See figure 1</strong>. <br>
                
                <h4>Decision Tree</h4>
                <li>During my decision tree project I encountered one very big problem when making my model. When I had made my decision tree model in my 
                python code I then was trying to visualize my model but I was having a lot of trouble when trying to achieve this. I used chatgpt 
                to help me with this problem. <strong>See figure 2</strong>. <br>
   
                <h4>Random Forest</h4>
                <li>During my random forest project I did not encounter too much problems, this is due to 
                me learning how to fix certain things from my two other projects and also I understand my dataset very well. <strong>See figure 3</strong>. <br>
            </ul>
                
            <strong>Figure 1</strong> Linear Regression Graph <br>
            <strong>Figure 2</strong> Decision Tree <br>
            <strong>Figure 3</strong> Random Forest <br>
            <br><br><br>
    
            <div class="dvv">
                <p>Figure 1</p><img id="figures" src="fig3.png">
                <p>Figure 2</p><img id="figures" src="my decision tree in colour.png">
                <p>Figure 3</p><img id="figures" src="random forest working with no error.png">
            </div>
            <br><br>
        </div>
    </section>


    <section id="about">
        <div class="container">
            <h2>Algorithms Online & Sources</h2>
            <p>During the development of my Linear Regression, Decision Tree and Random Forest 
            projects I found a few sources online that were a lot of help to me.</p>

            <h4>Linear Regression</h4>
            <p>During my linear regression project I used: Wiley see reference [1] and I also used Jake Vanderplas Python Book see reference [2]. 


            <h4><strong>Why did I use these?</strong></h4>
            I used wiley to do a bit of reading on linear regression before doing any coding and I also used Jake Vanderplas Python Book to get an 
            idea on how to code out a linear regression model in python. <br>
            <strong>Wiley</strong><a href="https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1380"> Wiley reference [1]</a>. <br>
            <strong>Jake Vanderplas Python Book</strong><a href="https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.06-Linear-Regression.ipynb"> Jake Vanderplas Python Book reference [2]</a>. <br><br>


            <h4>Decision Tree</h4>
            <p>During my decision tree project I used: W3Schools see reference [1], I used Mljar see reference [2] and I also used ChatGPT see reference [3].
            
            <h4><strong>Why did I use these?</strong></h4>
            I used w3schools to do some basic coding with a decision tree in python, I used mljar to help me visualize my decision tree and I used chatgpt to help me 
            to visualize to decision tree due to most of the websites being helpful but they did not work. <br>
            <strong>W3Schools</strong><a href="https://www.w3schools.com/python/python_ml_decision_tree.asp"> W3Schools reference [1]</a>. <br>
            <strong>Mljar</strong><a href="https://mljar.com/blog/visualize-decision-tree/"> Mljar reference [2]</a>. <br>
            <strong>ChatGPT</strong><a href="https://chatgpt.com/"> ChatGPT reference [3]</a>. <br><br>


            <h4>Random Forest</h4>
            <p>During my random forest project I used: data36 see reference [1] and I also used chatgpt see reference [2]. 
            
            <h4><strong>Why did I use these?</strong></h4>
            I used data36 to do some research on what a random forest is and how to program one, I also used chatgpt to help me visualize my random forest. <br>
            <strong>data36</strong><a href="https://data36.com/random-forest-in-python/"> data36 reference [1]</a>. <br>
            <strong>ChatGPT</strong><a href="https://chatgpt.com/"> ChatGPT reference [2]</a>. <br>

            <p></p> <br>
        </div>
    </section>


    <section id="about">
        <div class="container">
            <h2>Tool's & Technology Used</h2>
            <p>When I was developing my three projects I used the following technologies:</p>
          
            <h3 class="lr">Linear Regression</h3>
            <ul>
                <strong>Python</strong  > <br>
                <strong>Jupyter Notebook's</strong> <br>
                <strong>Matplotlib</strong> <br>
                <strong>Sklearn.linear_model</strong> <br>
                <strong>Pandas</strong> <br>
            </ul>

            <h3 class="dt">Decision Tree</h3>
            <ul>
                <strong>Python</strong> <br>
                <strong>Jupyter Notebook's</strong> <br>
                <strong>Matplotlib</strong> <br>
                <strong>Sklearn.linear_model</strong> <br>
                <strong>Pandas</strong> <br>
                <strong>Sklearn tree</strong> <br>
                <strong>Sklearn plot_tree</strong> <br>
                <strong>Sklearn.tree DecisionTreeClassifier</strong> <br>
                <strong>Sklearn.datasets load_iris</strong> <br>
            </ul>
            
            <h3 class="rf">Random Forest</h3>
            <ul>
                <strong>Python</strong> <br>
                <strong>Jupyter Notebook's</strong>  <br>
                <strong>Pandas</strong> <br>
                <strong>Matplotlib as plt</strong> <br>
                <strong>sklearn.tree plot_tree</strong> <br>  
                <strong>sklearn.model_selection train_test_split</strong> <br>
                <strong>sklearn.ensemble RandomForestClassifier</strong> <br>
            </ul>

            <p>During all of my projects I made I got quite familiar with some of the python libraries such as: Pandas, Matplotlib, Sklearn tree,  
            Sklearn.tree DecisionTreeClassifier, Sklearn.datasets load_iris and RandomForestClassifier.</p>

        	<p>All of the above technologies are a must when working with data science and machine learning, but particularly with Linear Regression, Decision Tree's and
            Random Forest.</p>
        </div>
    </section>  
</body>
</html>
